---
title: Full Stack Fest 2018
translationKey: full-stack-fest-2018
date: 2019-01-03
tags:
    - web
    - conferences
menu:
    main:
        parent: 'blog'
photoDesc: La Sagrada Familia — Erwan Hesry
photoUrl: https://unsplash.com/photos/QYYg0KwTGYc
---

Have you ever felt the urge to throw that bag full of useless things — the one they still give you on conferences despite common sense — on the stage? It happens to me. At that moment, instead of hard-won experiences or thoughts, you listen to something that resembles reading a documentation and, on top of that, the person on the stage pretends it's all so fascinating.

<!--more-->

Fortunately, such a thing happens rarely at [Full Stack Fest](https://fullstackfest.com/). It's a five-day conference, divided into two blocks, roughly labeled as back-end and front-end. And, although I have more to say about the latter, I am always happy to learn about the former, too. It doesn't hurt a bit that it all takes place in Barcelona. Two themes dominated this year: peer-to-peer technology and decentralization in general on the back-end, and performance and optimization in the world of front-end.

## The decentralization of the internet

Unlike the previous year, the word blockchain wasn't automatically thrown together with the word decentralization. But we got a glimpse of blockchain — or rather its private, toothless form — in a ~~advertising~~ [presentation from IBM](https://youtu.be/v2WiqQs_JAs), anyway. [The lecture by Andre Staltz](https://youtu.be/8GE5C9-RUpg) was way more intriguing. He talked about the sympatethic effort to replace the current model of social networks with a decentralized alternative. And since the cornerstone of every peer-to-peer network is a protocol, he described a solution based on a particular technology called [Scuttlebutt](https://www.scuttlebutt.nz/). When I asked how Scuttlebutt compares to Tim Berners-Lee's [project Solid](https://solid.mit.edu/) which seems to be solving a similar set of problems, Andre replied that while Solid started as a specification first and only then turned into an implementation, Scuttlebutt is the other way around. That path is more organic and wild, but certainly more engrossing for those entertaining the idea to get involved.

A similar topic, but a different point of view, was [presented by Tara Vancil](https://youtu.be/raUE23RKLvE). Tara is part of the team around the experimental [Beaker browser](https://beakerbrowser.com/). It confidently and directly targets one of the foundations of the internet, the HTTP protocol, and hopes to replace it with a protocol called [DAT](https://datproject.org/) which is built on the principles of peer-to-peer technology. Like BitTorrent, it breaks down the traditional arrangement of servers and clients, and replaces it with a complex network of peer nodes. If I want to contribute content (like a website), I need to get involved in the network and let my computer act as a type of "server", at least in the beginning. The more intriguing part comes next when, hopefully, some users visit my site. Then, they also become providers of the website, which means it's hosted on several different computers, the number of which is directly proportional to the website's popularity. This eliminates the need for my computer to be online at all times. As long as at least one of the nodes that have copy of the website is connected to the network, it should still be available. That makes it very hard to censor a popular content. At least compared to the current model of the internet, where it's easy to ban entire websites, like, for example, Wikipedia in Turkey.

The purpose of Beaker is to allow ordinary users to create and read such content, and to raise awareness of the alternative to the current internet. At the same time, it partially conceals the complexity that necessarily arises in decentralized networks. Whether we are talking about microservices, distributed databases, blockchain, or the promise of the so-called "Web 3.0", we will increasingly face this complexity both as creators and users. There's one thing I regret regarding Beaker, though. It doesn't (yet) support the [IPFS protocol](https://ipfs.io/), which is very similar to DAT and perhaps more well-known.

## The Holy Grail of optimalization?

From the front-end side of the fence, we got several contributions to the evergreen topic of optimalization. And despite some innovations, it still rings true that it's a treacherous area, with just a few signs of elegant solutions here and there.

Zásadní byla v tomto ohledu [přednáška od Patricka Hamanna](https://youtu.be/ga_-zsTHRm8), který díky svému angažmá ve Fastly — a podobně jako [Jake Archibald](https://jakearchibald.com/2017/h2-push-tougher-than-i-thought/) — ukázal, že takzvaný HTTP push je v praxi mnohem komplikovanější téma, než jsme si naivně mysleli. Server push byl jedním z příslibů protokolu HTTP2, který alespoň na papíře řeší základní problém optimalizace načtení webu. Jak klientovi co nejrychleji poslat všechny soubory nutné pro vykreslení stránky? Server ví přesně, které soubory to jsou, ale klient musí nejprve stáhnout a zpracovat HTML, aby získal přehled o dalších závislostech jako styly nebo obrázky. Server push umožňuje na základě jednoho požadavku místo pouhého HTML souboru poslat teoreticky všechny závislosti, aniž by si je klient sám vyžádal. Problém ovšem — jako obvykle — vzniká, když do úvah zapojíme cache. Ta se objevuje na několika úrovních (paměť, service worker, HTTP cache, a nově push cache), a navrch se v různých prohlížečích chová odlišně. Řešení samozřejmě není jednoduché a jako vždy je založené na kompromisech. V kombinaci se současnými a budoucími technikami jako [Cache Digest](https://tools.ietf.org/html/draft-ietf-httpbis-cache-digest-04), [Early Hints](https://tools.ietf.org/html/rfc8297) nebo [preloading](https://w3c.github.io/preload/) jde nicméně i tak o velký krok kupředu.

[Přednáška o nativních modulech v JavaScriptu](https://youtu.be/O4r9D2jI0_w), ve které Serg Hospodarets předvedl, že není důvod otálet vyzkoušet moduly na produkčním prostředí — ať už v prohlížeči nebo v Node.js — byla o mnoho veselejší. Ještě nějakou dobu se sice neobejdeme bez skriptů transpilovaných a zabalených do jednoho balíčku, ale díky direktivě `nomodule` můžeme těm prohlížečům, které moduly podporují, poslat výrazně méně dat a využít HTTP2 multiplexingu. Jedinou vadou je zatím nedostatečná podpora pro dynamické nahrávání modulů, a s tou nám bohužel žádná direktiva nepomůže.

Zack Argyle [vyprávěl](https://youtu.be/pluzva6Dk9Q), jak si v Pinterestu poradili s mobilním webem. Po prvotním rozhodnutí tlačit uživatele ke stažení nativní aplikace, které se ukázalo být neštastné (kdo by to čekal?), usoudili, že všechny síly naopak věnují právě mobilnímu webu a od základů ho předělají. Výsledkem jsou stránky postavené na Reactu a principech PWA (progressive web app). Výjimečná je v tomto ohledu snaha Pinterestu na poli optimalizace, kde využívají všech možností, od agresivního cachingu na úrovni service workeru, vykreslení části aplikace na serveru (server-side rendering), až po striktní limit na množství kódu, které musí uživatel stáhnout. Poslednímu bodu se věnovala i Sia Karamalegos. Ve své [prezentaci](https://youtu.be/SA_Hp8l7lr4) opakovala nepříliš známý fakt, že ačkoliv v množství stažených dat stále vedou obrázky, je skutečným „vítězem“ JavaScript. Důvod tkví v tom, že každý byte kódu vyžaduje větší množství operací nutných pro jeho zpracování než v případě obrázku, tudíž i více zatěžuje procesor, jehož kapacity obzvlášť na mobilních zařízení nejsou neomezené.

Na závěr doporučuju zhlédnout [video](https://youtu.be/K0WU02flF_E), kde Andrew Louis ukazuje, jak to vypadá, když se pokusíte zaznamenat co největší množství detailů z vlastního života v digitální podobě. Andrew se toho snaží dosáhnout tak, že vytvořil a dále vyvíjí [moderní verzi memexu](https://hyfen.net/memex/) — ideového předchůdce hypertextu. Pokud máte úchylku na organizaci dat nebo se naopak obáváte, že to občas přeháníte s digitálním životem na úkor toho skutečného, možná vás přednáška uklidní.